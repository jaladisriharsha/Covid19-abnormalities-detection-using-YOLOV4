{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-23T13:55:15.786278Z",
     "iopub.status.busy": "2021-07-23T13:55:15.785926Z",
     "iopub.status.idle": "2021-07-23T13:55:16.771953Z",
     "shell.execute_reply": "2021-07-23T13:55:16.771078Z",
     "shell.execute_reply.started": "2021-07-23T13:55:15.786243Z"
    }
   },
   "outputs": [],
   "source": [
    "# Necessary/extra dependencies. \n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T13:55:21.060094Z",
     "iopub.status.busy": "2021-07-23T13:55:21.059759Z",
     "iopub.status.idle": "2021-07-23T13:55:21.06511Z",
     "shell.execute_reply": "2021-07-23T13:55:21.064224Z",
     "shell.execute_reply.started": "2021-07-23T13:55:21.060063Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'input/siim-covid19-resized-to-256px-jpg/train/'\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T14:01:07.24478Z",
     "iopub.status.busy": "2021-07-23T14:01:07.244417Z",
     "iopub.status.idle": "2021-07-23T14:01:07.592416Z",
     "shell.execute_reply": "2021-07-23T14:01:07.591579Z",
     "shell.execute_reply.started": "2021-07-23T14:01:07.244747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Everything is done from /kaggle directory.\n",
    "%cd ../\n",
    "\n",
    "# Load image level csv file\n",
    "df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')\n",
    "\n",
    "# Modify values in the id column\n",
    "df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)\n",
    "# Add absolute path\n",
    "df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)\n",
    "# Get image level labels\n",
    "df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T14:01:11.811809Z",
     "iopub.status.busy": "2021-07-23T14:01:11.811466Z",
     "iopub.status.idle": "2021-07-23T14:01:11.84363Z",
     "shell.execute_reply": "2021-07-23T14:01:11.842868Z",
     "shell.execute_reply.started": "2021-07-23T14:01:11.811778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load meta.csv file\n",
    "# Original dimensions are required to scale the bounding box coordinates appropriately.\n",
    "meta_df = pd.read_csv('input/siim-covid19-resized-to-256px-jpg/meta.csv')\n",
    "train_meta_df = meta_df.loc[meta_df.split == 'train']\n",
    "train_meta_df = train_meta_df.drop('split', axis=1)\n",
    "train_meta_df.columns = ['id', 'dim0', 'dim1']\n",
    "\n",
    "train_meta_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T14:01:13.282328Z",
     "iopub.status.busy": "2021-07-23T14:01:13.281981Z",
     "iopub.status.idle": "2021-07-23T14:01:13.309302Z",
     "shell.execute_reply": "2021-07-23T14:01:13.308509Z",
     "shell.execute_reply.started": "2021-07-23T14:01:13.282295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge both the dataframes\n",
    "df = df.merge(train_meta_df, on='id',how=\"left\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-07-23T14:01:18.402536Z",
     "iopub.status.busy": "2021-07-23T14:01:18.402208Z",
     "iopub.status.idle": "2021-07-23T14:01:18.436993Z",
     "shell.execute_reply": "2021-07-23T14:01:18.435973Z",
     "shell.execute_reply.started": "2021-07-23T14:01:18.402504Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create train and validation split.\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df.image_level.values)\n",
    "\n",
    "train_df.loc[:, 'split'] = 'train'\n",
    "valid_df.loc[:, 'split'] = 'valid'\n",
    "\n",
    "df = pd.concat([train_df, valid_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T14:01:25.984265Z",
     "iopub.status.busy": "2021-07-23T14:01:25.983942Z",
     "iopub.status.idle": "2021-07-23T14:01:25.988978Z",
     "shell.execute_reply": "2021-07-23T14:01:25.988094Z",
     "shell.execute_reply.started": "2021-07-23T14:01:25.984235Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Size of dataset: {len(df)}, training images: {len(train_df)}. validation images: {len(valid_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T14:03:34.675946Z",
     "iopub.status.busy": "2021-07-23T14:03:34.675397Z",
     "iopub.status.idle": "2021-07-23T14:03:35.364254Z",
     "shell.execute_reply": "2021-07-23T14:03:35.363162Z",
     "shell.execute_reply.started": "2021-07-23T14:03:34.675893Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs('tmp/covid/images/train', exist_ok=True)\n",
    "os.makedirs('tmp/covid/images/valid', exist_ok=True)\n",
    "\n",
    "os.makedirs('tmp/covid/labels/train', exist_ok=True)\n",
    "os.makedirs('tmp/covid/labels/valid', exist_ok=True)\n",
    "\n",
    "! ls tmp/covid/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T14:03:38.664796Z",
     "iopub.status.busy": "2021-07-23T14:03:38.66442Z",
     "iopub.status.idle": "2021-07-23T14:04:18.001121Z",
     "shell.execute_reply": "2021-07-23T14:04:18.000253Z",
     "shell.execute_reply.started": "2021-07-23T14:03:38.664763Z"
    }
   },
   "outputs": [],
   "source": [
    "# Move the images to relevant split folder.\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = df.loc[i]\n",
    "    if row.split == 'train':\n",
    "        copyfile(row.path, f'tmp/covid/images/train/{row.id}.jpg')\n",
    "    else:\n",
    "        copyfile(row.path, f'tmp/covid/images/valid/{row.id}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `.YAML` file\n",
    "\n",
    "The `data.yaml`, is the dataset configuration file that defines \n",
    "\n",
    "1. an \"optional\" download command/URL for auto-downloading, \n",
    "2. a path to a directory of training images (or path to a *.txt file with a list of training images), \n",
    "3. a path to a directory of validation images (or path to a *.txt file with a list of validation images), \n",
    "4. the number of classes, \n",
    "5. a list of class names.\n",
    "\n",
    "> Important: In this competition, each image can either belong to `opacity` or `none` image-level labels. That's why I have  used the number of classes, `nc` to be 2. YOLOv5 automatically handles the images without any bounding box coordinates. \n",
    "\n",
    "> Note: The `data.yaml` is created in the `yolov5/data` directory as required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T14:04:23.9742Z",
     "iopub.status.busy": "2021-07-23T14:04:23.973856Z",
     "iopub.status.idle": "2021-07-23T14:04:24.663031Z",
     "shell.execute_reply": "2021-07-23T14:04:24.662068Z",
     "shell.execute_reply.started": "2021-07-23T14:04:23.97416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create .yaml file \n",
    "import yaml\n",
    "\n",
    "data_yaml = dict(\n",
    "    train = '../covid/images/train',\n",
    "    val = '../covid/images/valid',\n",
    "    nc = 2,\n",
    "    names = ['none', 'opacity']\n",
    ")\n",
    "\n",
    "# Note that I am creating the file in the yolov5/data/ directory.\n",
    "with open('tmp/yolov5/data/data.yaml', 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)\n",
    "    \n",
    "%cat tmp/yolov5/data/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Bounding Box Coordinated for YOLOv5\n",
    "\n",
    "For every image with **bounding box(es)** a `.txt` file with the same name as the image will be created in the format shown below:\n",
    "\n",
    "* One row per object. <br>\n",
    "* Each row is class `x_center y_center width height format`. <br>\n",
    "* Box coordinates must be in normalized xywh format (from 0 - 1). We can normalize by the boxes in pixels by dividing `x_center` and `width` by image width, and `y_center` and `height` by image height. <br>\n",
    "* Class numbers are zero-indexed (start from 0). <br>\n",
    "\n",
    "> Note: We don't have to remove the images without bounding boxes from the training or validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T18:10:10.698966Z",
     "iopub.status.busy": "2021-05-23T18:10:10.698643Z",
     "iopub.status.idle": "2021-05-23T18:10:10.710508Z",
     "shell.execute_reply": "2021-05-23T18:10:10.70946Z",
     "shell.execute_reply.started": "2021-05-23T18:10:10.698933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the raw bounding box by parsing the row value of the label column.\n",
    "# Ref: https://www.kaggle.com/yujiariyasu/plot-3positive-classes\n",
    "def get_bbox(row):\n",
    "    bboxes = []\n",
    "    bbox = []\n",
    "    for i, l in enumerate(row.label.split(' ')):\n",
    "        if (i % 6 == 0) | (i % 6 == 1):\n",
    "            continue\n",
    "        bbox.append(float(l))\n",
    "        if i % 6 == 5:\n",
    "            bboxes.append(bbox)\n",
    "            bbox = []  \n",
    "            \n",
    "    return bboxes\n",
    "\n",
    "# Scale the bounding boxes according to the size of the resized image. \n",
    "def scale_bbox(row, bboxes):\n",
    "    # Get scaling factor\n",
    "    scale_x = IMG_SIZE/row.dim1\n",
    "    scale_y = IMG_SIZE/row.dim0\n",
    "    \n",
    "    scaled_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        x = int(np.round(bbox[0]*scale_x, 4))\n",
    "        y = int(np.round(bbox[1]*scale_y, 4))\n",
    "        x1 = int(np.round(bbox[2]*(scale_x), 4))\n",
    "        y1= int(np.round(bbox[3]*scale_y, 4))\n",
    "\n",
    "        scaled_bboxes.append([x, y, x1, y1]) # xmin, ymin, xmax, ymax\n",
    "        \n",
    "    return scaled_bboxes\n",
    "\n",
    "# Convert the bounding boxes in YOLO format.\n",
    "def get_yolo_format_bbox(img_w, img_h, bboxes):\n",
    "    yolo_boxes = []\n",
    "    for bbox in bboxes:\n",
    "        w = bbox[2] - bbox[0] # xmax - xmin\n",
    "        h = bbox[3] - bbox[1] # ymax - ymin\n",
    "        xc = bbox[0] + int(np.round(w/2)) # xmin + width/2\n",
    "        yc = bbox[1] + int(np.round(h/2)) # ymin + height/2\n",
    "        \n",
    "        yolo_boxes.append([xc/img_w, yc/img_h, w/img_w, h/img_h]) # x_center y_center width height\n",
    "    \n",
    "    return yolo_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T18:13:14.619879Z",
     "iopub.status.busy": "2021-05-23T18:13:14.619568Z",
     "iopub.status.idle": "2021-05-23T18:13:17.406088Z",
     "shell.execute_reply": "2021-05-23T18:13:17.405103Z",
     "shell.execute_reply.started": "2021-05-23T18:13:14.61985Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the txt files for bounding box\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = df.loc[i]\n",
    "    # Get image id\n",
    "    img_id = row.id\n",
    "    # Get split\n",
    "    split = row.split\n",
    "    # Get image-level label\n",
    "    label = row.image_level\n",
    "    \n",
    "    if row.split=='train':\n",
    "        file_name = f'tmp/covid/labels/train/{row.id}.txt'\n",
    "    else:\n",
    "        file_name = f'tmp/covid/labels/valid/{row.id}.txt'\n",
    "        \n",
    "    \n",
    "    if label=='opacity':\n",
    "        # Get bboxes\n",
    "        bboxes = get_bbox(row)\n",
    "        # Scale bounding boxes\n",
    "        scale_bboxes = scale_bbox(row, bboxes)\n",
    "        # Format for YOLOv5\n",
    "        yolo_bboxes = get_yolo_format_bbox(IMG_SIZE, IMG_SIZE, scale_bboxes)\n",
    "        \n",
    "        with open(file_name, 'w') as f:\n",
    "            for bbox in yolo_bboxes:\n",
    "                bbox = [1]+bbox\n",
    "                bbox = [str(i) for i in bbox]\n",
    "                bbox = ' '.join(bbox)\n",
    "                f.write(bbox)\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with W&B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T23:38:03.562896Z",
     "iopub.status.busy": "2021-05-23T23:38:03.562575Z",
     "iopub.status.idle": "2021-05-23T23:38:03.5705Z",
     "shell.execute_reply": "2021-05-23T23:38:03.569539Z",
     "shell.execute_reply.started": "2021-05-23T23:38:03.562868Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd tmp/yolov5/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "--img {IMG_SIZE} \\ # Input image size.\n",
    "--batch {BATCH_SIZE} \\ # Batch size\n",
    "--epochs {EPOCHS} \\ # Number of epochs\n",
    "--data data.yaml \\ # Configuration file\n",
    "--weights yolov5s.pt \\ # Model name\n",
    "--save_period 1\\ # Save model after interval\n",
    "--project kaggle-siim-covid # W&B project name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T18:13:45.999586Z",
     "iopub.status.busy": "2021-05-23T18:13:45.999265Z",
     "iopub.status.idle": "2021-05-23T18:22:29.021193Z",
     "shell.execute_reply": "2021-05-23T18:22:29.02019Z",
     "shell.execute_reply.started": "2021-05-23T18:13:45.999557Z"
    }
   },
   "outputs": [],
   "source": [
    "!python train.py --img {IMG_SIZE} \\\n",
    "                 --batch {BATCH_SIZE} \\\n",
    "                 --epochs {EPOCHS} \\\n",
    "                 --data data.yaml \\\n",
    "                 --weights yolov5s.pt \\\n",
    "                 --save_period 1\\\n",
    "                 --project kaggle-siim-covid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "You will probably use a `Submission.ipynb` kernel to run all the predictions. After training a YOLOv5 based object detector -> head to the artifacts page and download the best model -> upload the model as a Kaggle dataset -> Use it with the submission folder. \n",
    "\n",
    "> Note that you might have to clone the YOLOv5 repository in a Kaggle dataset as well. \n",
    "\n",
    "In this section, I will show you how you can do the inference and modify the predicted bounding box coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T19:07:49.662836Z",
     "iopub.status.busy": "2021-05-23T19:07:49.662496Z",
     "iopub.status.idle": "2021-05-23T19:07:49.66761Z",
     "shell.execute_reply": "2021-05-23T19:07:49.666279Z",
     "shell.execute_reply.started": "2021-05-23T19:07:49.662804Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_PATH = '/kaggle/input/siim-covid19-resized-to-256px-jpg/test/' # absolute path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am training the model in this kernel itself, I will not be using the method that I have described above. The best model is saved in the directory `project_name/exp*/weights/best.pt`. In `exp*`, * can be 1, 2, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T19:07:51.844324Z",
     "iopub.status.busy": "2021-05-23T19:07:51.843949Z",
     "iopub.status.idle": "2021-05-23T19:07:51.848162Z",
     "shell.execute_reply": "2021-05-23T19:07:51.847242Z",
     "shell.execute_reply.started": "2021-05-23T19:07:51.844293Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = 'kaggle-siim-covid/exp/weights/best.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "--weights {MODEL_PATH} \\ # path to the best model.\n",
    "--source {TEST_PATH} \\ # absolute path to the test images.\n",
    "--img {IMG_SIZE} \\ # Size of image\n",
    "--conf 0.281 \\ # Confidence threshold (default is 0.25)\n",
    "--iou-thres 0.5 \\ # IOU threshold (default is 0.45)\n",
    "--max-det 3 \\ # Number of detections per image (default is 1000) \n",
    "--save-txt \\ # Save predicted bounding box coordinates as txt files\n",
    "--save-conf # Save the confidence of prediction for each bounding box\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-05-23T19:12:25.325905Z",
     "iopub.status.busy": "2021-05-23T19:12:25.325558Z",
     "iopub.status.idle": "2021-05-23T19:13:05.525279Z",
     "shell.execute_reply": "2021-05-23T19:13:05.524304Z",
     "shell.execute_reply.started": "2021-05-23T19:12:25.325875Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python detect.py --weights {MODEL_PATH} \\\n",
    "                  --source {TEST_PATH} \\\n",
    "                  --img {IMG_SIZE} \\\n",
    "                  --conf 0.281 \\\n",
    "                  --iou-thres 0.5 \\\n",
    "                  --max-det 3 \\\n",
    "                  --save-txt \\\n",
    "                  --save-conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The bounding box coordinates are saved as text file per image name. It is saved in this directory `runs/detect/exp3/labels`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-05-23T23:49:10.27145Z",
     "iopub.status.busy": "2021-05-23T23:49:10.271105Z",
     "iopub.status.idle": "2021-05-23T23:49:10.900773Z",
     "shell.execute_reply": "2021-05-23T23:49:10.899874Z",
     "shell.execute_reply.started": "2021-05-23T23:49:10.271418Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PRED_PATH = 'runs/detect/exp3/labels'\n",
    "!ls {PRED_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T23:49:14.79253Z",
     "iopub.status.busy": "2021-05-23T23:49:14.792212Z",
     "iopub.status.idle": "2021-05-23T23:49:15.427611Z",
     "shell.execute_reply": "2021-05-23T23:49:15.426681Z",
     "shell.execute_reply.started": "2021-05-23T23:49:14.792498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize predicted coordinates.\n",
    "%cat runs/detect/exp3/labels/ba91d37ee459.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: 1 is class id (opacity), the first four float numbers are `x_center`, `y_center`, `width` and `height`. The final float value is `confidence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T23:49:17.65575Z",
     "iopub.status.busy": "2021-05-23T23:49:17.655442Z",
     "iopub.status.idle": "2021-05-23T23:49:17.661362Z",
     "shell.execute_reply": "2021-05-23T23:49:17.660382Z",
     "shell.execute_reply.started": "2021-05-23T23:49:17.655721Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_files = os.listdir(PRED_PATH)\n",
    "print('Number of test images predicted as opaque: ', len(prediction_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Out of 1263 test images, 583 were predicted with `opacity` label and thus we have that many prediction txt files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "In this section, I will show how you can use YOLOv5 as object detector and prepare `submission.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-05-24T00:04:32.640474Z",
     "iopub.status.busy": "2021-05-24T00:04:32.640121Z",
     "iopub.status.idle": "2021-05-24T00:04:32.649309Z",
     "shell.execute_reply": "2021-05-24T00:04:32.64846Z",
     "shell.execute_reply.started": "2021-05-24T00:04:32.640442Z"
    }
   },
   "outputs": [],
   "source": [
    "# The submisison requires xmin, ymin, xmax, ymax format. \n",
    "# YOLOv5 returns x_center, y_center, width, height\n",
    "def correct_bbox_format(bboxes):\n",
    "    correct_bboxes = []\n",
    "    for b in bboxes:\n",
    "        xc, yc = int(np.round(b[0]*IMG_SIZE)), int(np.round(b[1]*IMG_SIZE))\n",
    "        w, h = int(np.round(b[2]*IMG_SIZE)), int(np.round(b[3]*IMG_SIZE))\n",
    "\n",
    "        xmin = xc - int(np.round(w/2))\n",
    "        xmax = xc + int(np.round(w/2))\n",
    "        ymin = yc - int(np.round(h/2))\n",
    "        ymax = yc + int(np.round(h/2))\n",
    "        \n",
    "        correct_bboxes.append([xmin, xmax, ymin, ymax])\n",
    "        \n",
    "    return correct_bboxes\n",
    "\n",
    "# Read the txt file generated by YOLOv5 during inference and extract \n",
    "# confidence and bounding box coordinates.\n",
    "def get_conf_bboxes(file_path):\n",
    "    confidence = []\n",
    "    bboxes = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            preds = line.strip('\\n').split(' ')\n",
    "            preds = list(map(float, preds))\n",
    "            confidence.append(preds[-1])\n",
    "            bboxes.append(preds[1:-1])\n",
    "    return confidence, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T00:04:43.958403Z",
     "iopub.status.busy": "2021-05-24T00:04:43.958093Z",
     "iopub.status.idle": "2021-05-24T00:04:43.97789Z",
     "shell.execute_reply": "2021-05-24T00:04:43.977167Z",
     "shell.execute_reply.started": "2021-05-24T00:04:43.958375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the submisison file\n",
    "sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\n",
    "sub_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T00:05:07.787407Z",
     "iopub.status.busy": "2021-05-24T00:05:07.787078Z",
     "iopub.status.idle": "2021-05-24T00:05:08.160354Z",
     "shell.execute_reply": "2021-05-24T00:05:08.159234Z",
     "shell.execute_reply.started": "2021-05-24T00:05:07.787378Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction loop for submission\n",
    "predictions = []\n",
    "\n",
    "for i in tqdm(range(len(sub_df))):\n",
    "    row = sub_df.loc[i]\n",
    "    id_name = row.id.split('_')[0]\n",
    "    id_level = row.id.split('_')[-1]\n",
    "    \n",
    "    if id_level == 'study':\n",
    "        # do study-level classification\n",
    "        predictions.append(\"Negative 1 0 0 1 1\") # dummy prediction\n",
    "        \n",
    "    elif id_level == 'image':\n",
    "        # we can do image-level classification here.\n",
    "        # also we can rely on the object detector's classification head.\n",
    "        # for this example submisison we will use YOLO's classification head. \n",
    "        # since we already ran the inference we know which test images belong to opacity.\n",
    "        if f'{id_name}.txt' in prediction_files:\n",
    "            # opacity label\n",
    "            confidence, bboxes = get_conf_bboxes(f'{PRED_PATH}/{id_name}.txt')\n",
    "            bboxes = correct_bbox_format(bboxes)\n",
    "            pred_string = ''\n",
    "            for j, conf in enumerate(confidence):\n",
    "                pred_string += f'opacity {conf} ' + ' '.join(map(str, bboxes[j])) + ' '\n",
    "            predictions.append(pred_string[:-1]) \n",
    "        else:\n",
    "            predictions.append(\"None 1 0 0 1 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T00:05:14.382937Z",
     "iopub.status.busy": "2021-05-24T00:05:14.382633Z",
     "iopub.status.idle": "2021-05-24T00:05:14.406141Z",
     "shell.execute_reply": "2021-05-24T00:05:14.405412Z",
     "shell.execute_reply.started": "2021-05-24T00:05:14.382909Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df['PredictionString'] = predictions\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "sub_df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
